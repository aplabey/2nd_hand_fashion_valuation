{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"~/code/aplabey/2nd_hand_fashion_valuation/raw_data/vestiaire.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"has_cross_border_fees\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of NaN for each column\n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the percentage of NaN for each column\n",
    "data.isnull().sum().sort_values(ascending=False) / len(data) #NaN percentage for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_brand = data.groupby('brand_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts = grouped_by_brand.size().sort_values(ascending=False)\n",
    "brand_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discuss about threshold (useful? size?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "brands_with_few_counts = brand_counts[brand_counts < threshold]\n",
    "brands_with_few_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_mapping = {brand: brand if count >= threshold else 'Others'\n",
    "                 for brand, count in brand_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['brand_name'] = data['brand_name'].map(brand_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts = data['brand_name'].value_counts()\n",
    "brand_counts.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_price_mean = grouped_by_brand['price_usd'].mean().sort_values(ascending=False)\n",
    "brand_price_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"price_usd\"]].boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_brands = data['brand_name'].value_counts().head(20).index\n",
    "filtered_data = data[data['brand_name'].isin(top_20_brands)]\n",
    "# Filter the DataFrame to include only the top 20 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(x='brand_name', y='price_usd', data=filtered_data)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Boxplot of Prices by Top 20 Most Common Brands')\n",
    "plt.xlabel('Brand')\n",
    "plt.ylabel('Price')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the indexes corresponding to rows \n",
    "# without very high values (price < 200.000)\n",
    "boolean_mask = (filtered_data['price_usd']<20000) \n",
    "\n",
    "# Apply the boolean filtering\n",
    "filtered_data_boolean = filtered_data[boolean_mask].reset_index(drop=True)\n",
    "\n",
    "# Visualize the boxplot again\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(x='brand_name', y='price_usd', data=filtered_data_boolean)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Boxplot of Prices by Top 20 Most Common Brands')\n",
    "plt.xlabel('Brand')\n",
    "plt.ylabel('Price')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 1: Calculate the overall most frequent value\n",
    "overall_most_frequent_value = data['usually_ships_within'].mode()[0]\n",
    "\n",
    "# Step 2: Define the imputation function\n",
    "def impute_most_frequent(group):\n",
    "    # Check if all values in the group are missing\n",
    "    if group['usually_ships_within'].isnull().all():\n",
    "        # Impute with the overall most frequent value\n",
    "        group['usually_ships_within'] = overall_most_frequent_value\n",
    "    else:\n",
    "        imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        # Reshape to 2D array because SimpleImputer expects it\n",
    "        group_reshaped = group[['usually_ships_within']].values.reshape(-1, 1)\n",
    "        imputed = imputer.fit_transform(group_reshaped)\n",
    "        group['usually_ships_within'] = imputed.ravel()\n",
    "    return group\n",
    "\n",
    "# Step 3: Group by 'brand_name' and apply the imputation function\n",
    "data = data.groupby('brand_name').apply(impute_most_frequent).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the percentage of NaN for each column\n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['buyers_fees', 'has_cross_border_fees'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.dropna()\n",
    "data_cleaned.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product_like_count\n",
    "#### As it is very skewed I chose Robust Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Transformation/Engineering\n",
    "\n",
    "If your feature is extremely skewed  \n",
    "â†’\n",
    "  consider Feature Engineering first (e.g. log(feature))\n",
    "shell we do this?\n",
    "\n",
    "# The following code is just how we would do without brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data_cleaned, x='product_like_count');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify the top 20 most common brands\n",
    "top_brands = data_cleaned['brand_name'].value_counts().head(20).index\n",
    "\n",
    "# Step 2: Filter the data to only include these top brands\n",
    "filtered_data = data_cleaned[data_cleaned['brand_name'].isin(top_brands)]\n",
    "\n",
    "# Step 3: Plot the histogram\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for better readability\n",
    "likes_hist = sns.histplot(filtered_data, x='product_like_count', hue='brand_name', bins=200, kde=True)\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.title('Distribution of Product Like Count for Top 20 Brands')\n",
    "plt.xlabel('Product Like Count')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Make sure that brand_name is only a column and not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Function to apply RobustScaler to each group\n",
    "def scale_group(group):\n",
    "    rb_scaler = RobustScaler()\n",
    "    group['product_like_count'] = rb_scaler.fit_transform(group[['product_like_count']])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "# Using group_keys=False to avoid adding the group name back as an index level\n",
    "data_cleaned = data_cleaned.groupby('brand_name', group_keys=False).apply(scale_group)\n",
    "\n",
    "\n",
    "# Reset the index to ensure 'brand_name' is a column, not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller_products_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the histogram\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for better readability\n",
    "products_sold_hist = sns.histplot(filtered_data, x='seller_products_sold', hue='brand_name', bins=200, kde=True)\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.title('Distribution of Products sold per Seller for Top 20 Brands')\n",
    "plt.xlabel('Products sold per Seller')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_group(group):\n",
    "    rb_scaler = RobustScaler()\n",
    "    group['seller_products_sold'] = rb_scaler.fit_transform(group[['seller_products_sold']])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "# Using group_keys=False to avoid adding the group name back as an index level\n",
    "data_cleaned = data_cleaned.groupby('brand_name', group_keys=False).apply(scale_group)\n",
    "\n",
    "\n",
    "# Reset the index to ensure 'brand_name' is a column, not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller_num_products_listed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the histogram\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for better readability\n",
    "products_listed_hist = sns.histplot(filtered_data, x='seller_num_products_listed', hue='brand_name', bins=200, kde=True)\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.title('Distribution of Products listed per Seller for Top 20 Brands')\n",
    "plt.xlabel('Products listed per Seller')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_group(group):\n",
    "    rb_scaler = RobustScaler()\n",
    "    group['seller_num_products_listed'] = rb_scaler.fit_transform(group[['seller_num_products_listed']])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "# Using group_keys=False to avoid adding the group name back as an index level\n",
    "data_cleaned = data_cleaned.groupby('brand_name', group_keys=False).apply(scale_group)\n",
    "\n",
    "\n",
    "# Reset the index to ensure 'brand_name' is a column, not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller_community_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the histogram\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for better readability\n",
    "community_rank_hist = sns.histplot(filtered_data, x='seller_community_rank', hue='brand_name', bins=200, kde=True)\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.title('Sellers community rank for Top 20 Brands')\n",
    "plt.xlabel('Community Rank per Seller')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_group(group):\n",
    "    rb_scaler = RobustScaler()\n",
    "    group['seller_community_rank'] = rb_scaler.fit_transform(group[['seller_community_rank']])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "# Using group_keys=False to avoid adding the group name back as an index level\n",
    "data_cleaned = data_cleaned.groupby('brand_name', group_keys=False).apply(scale_group)\n",
    "\n",
    "\n",
    "# Reset the index to ensure 'brand_name' is a column, not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller_num_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the histogram\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for better readability\n",
    "num_followers_hist = sns.histplot(filtered_data, x='seller_num_followers', hue='brand_name', bins=200, kde=True)\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.title('Number of Followers per Seller for Top 20 Brands')\n",
    "plt.xlabel('Follower per Seller')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_group(group):\n",
    "    rb_scaler = RobustScaler()\n",
    "    group['seller_num_followers'] = rb_scaler.fit_transform(group[['seller_num_followers']])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "# Using group_keys=False to avoid adding the group name back as an index level\n",
    "data_cleaned = data_cleaned.groupby('brand_name', group_keys=False).apply(scale_group)\n",
    "\n",
    "\n",
    "# Reset the index to ensure 'brand_name' is a column, not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seller_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the histogram\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for better readability\n",
    "pass_rate_hist = sns.histplot(filtered_data, x='seller_pass_rate', hue='brand_name', bins=200, kde=True)\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.title('Pass Rate per Seller for Top 20 Brands')\n",
    "plt.xlabel('Pass Rate per Seller')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_group(group):\n",
    "    rb_scaler = RobustScaler()\n",
    "    group['seller_pass_rate'] = rb_scaler.fit_transform(group[['seller_pass_rate']])\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "# Using group_keys=False to avoid adding the group name back as an index level\n",
    "data_cleaned = data_cleaned.groupby('brand_name', group_keys=False).apply(scale_group)\n",
    "\n",
    "\n",
    "# Reset the index to ensure 'brand_name' is a column, not an index\n",
    "data_cleaned = data_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product_gender_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Check unique values for streets (3)\n",
    "print(f\"The unique values for 'Product_gender_target' are {data_cleaned.product_gender_target.unique()}\")\n",
    "\n",
    "# Instantiate the OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output = False) \n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(data_cleaned[['product_gender_target']]) \n",
    "\n",
    "# Display the detected categories\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n",
    "\n",
    "# Transform the current \"Street\" column\n",
    "data_cleaned[ohe.get_feature_names_out()] = ohe.transform(data_cleaned[['product_gender_target']])\n",
    "\n",
    "# Drop the column \"Street\" which has been encoded\n",
    "data_cleaned = data_cleaned.drop(columns = [\"product_gender_target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataset\n",
    "data_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the Correlartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Standard import for matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your plotting code\n",
    "correlation_matrix = data_cleaned.select_dtypes('number').corr()\n",
    "column_names = correlation_matrix.columns\n",
    "sns.heatmap(correlation_matrix, xticklabels=column_names, yticklabels=column_names, cmap=\"bwr\")\n",
    "\n",
    "# Make sure to show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the correlation matrix into a DataFrame\n",
    "corr_df = correlation_matrix.stack().reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "corr_df.columns = ['feature_1','feature_2', 'correlation']\n",
    "\n",
    "# Remove \"self correlations\"\n",
    "no_self_correlation = (corr_df['feature_1'] != corr_df['feature_2'])\n",
    "corr_df = corr_df[no_self_correlation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the absolute correlation\n",
    "corr_df['absolute_correlation'] = np.abs(corr_df['correlation'])\n",
    "\n",
    "# Showe the top 5 most correlated pairs of feature\n",
    "corr_df.sort_values(by=\"absolute_correlation\", ascending=False).head(15*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
